{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHXnMyHJZLBxkxZkCqkHRv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AashRoxx/Data_science_projects/blob/main/Brown_corpus_Tagging/NLP_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question statement:**\n",
        "Create a regular expression tagger \n",
        "and various unigram and n-gram \n",
        "taggers, incorporating backoff, and \n",
        "train them on part of the Brown \n",
        "corpus.\n",
        "1. Create three different \n",
        "combinations of the taggers. \n",
        "Test the accuracy of each \n",
        "combined tagger. Which \n",
        "combination works best?\n",
        "2. Try varying the size of the \n",
        "training corpus. How does it \n",
        "affect your results?"
      ],
      "metadata": {
        "id": "BP5qC5VLewtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer statement:**\n",
        "\n",
        "**1.** The three diffrent combinations of taggers are tr, t1, t2.\n",
        "*   t0 is the default tagger\n",
        "*   tr can backoff to t0\n",
        "*   t1 can backoff to tr then t0\n",
        "*   t2 can backoff to t1 then tr then to t0\n",
        "\n",
        "After checking the accuracy of each combined tagger we get t2 as the best  tagger. The best tagger combination is the kind that moves from most specific to most general. So the default tagger and the regex tagger are the last backoff obviously\n",
        "\n",
        "\n",
        "\n",
        "**2.**   We have tried three diffrent scenarios with varying size of the training corpus.\n",
        "\n",
        "*   In scenario 1, we considered the training set as 1 size long. The model does not get to train well hence the accuracy of all the different tagger combinations is very less.\n",
        "*   In scenario 2, we considered the training set as 2000 size long. The model trains realtively well as it has a longer traing set hence the accuracy of all the different tagger combinations is much better than scenario 1.\n",
        "*   In scenario 3, we considered the training set as 4636 size long. The model trains very well and the test set is one size long hence the accuracy is very high as well. Much better than scenario 1 and scenario 2.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HY2XSyBcvH99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "import nltk                                       \n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbmqCFlXfDTU",
        "outputId": "96232f98-8b35-45ef-927f-a9b8cc339c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chosing a category in the tagged sentences to explore in this case we have chosen the category adventure\n",
        "tagged_sents = brown.tagged_sents(categories='adventure')"
      ],
      "metadata": {
        "id": "yUJfep5zfapb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max_size is the length of the tagged sentences in the adventure category\n",
        "#it is the maximum value for the \"size\" variable\n",
        "max_size = int(len(tagged_sents))\n",
        "max_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmvDZkPTfasr",
        "outputId": "6538f5b8-d6b2-4801-c1ed-5e93093fff1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4637"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining patterns variable that the regular expressions tagger needs predefined.\n",
        "patterns = [\n",
        "     (r'.*ing$', 'VBG'),               # gerunds\n",
        "     (r'.*ed$', 'VBD'),                # simple past\n",
        "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
        "     (r'.*ould$', 'MD'),               # modals\n",
        "     (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
        "     (r'.*s$', 'NNS'),                 # plural nouns\n",
        "     (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
        "     (r'.*', 'NN')                     # nouns (default)\n",
        "     ]"
      ],
      "metadata": {
        "id": "nAbk5DZvfavj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scenario 1\n",
        "size=1                                                        # taking the value of variable \"size\" as 1\n",
        "train_sentences = tagged_sents[:size]                         # training set is 1 word long (very small)\n",
        "test_sentences = tagged_sents[size:]                          # test set is max_size-1 long = 4636\n",
        "#defining the taggers \n",
        "t0 = nltk.DefaultTagger('NN')                                 \n",
        "tr = nltk.RegexpTagger(patterns, backoff=t0)\n",
        "t1 = nltk.UnigramTagger(train_sentences, backoff=tr)\n",
        "t2 = nltk.BigramTagger(train_sentences, backoff=t1)\n",
        "#checking accuracy of the taggers\n",
        "print(t0.accuracy(test_sentences))\n",
        "print(tr.accuracy(test_sentences))\n",
        "print(t1.accuracy(test_sentences))\n",
        "print(t2.accuracy(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wNhBP5wfayU",
        "outputId": "dd5ec9c3-9470-417f-c972-26f80338e2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1161224254312583\n",
            "0.19012865632031387\n",
            "0.2618992672936018\n",
            "0.2618992672936018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scenario 2\n",
        "size=2000                                                     # taking the value of variable \"size\" as 2000\n",
        "train_sentences = tagged_sents[:size]                         # training set is 2000 word long (moderate)\n",
        "test_sentences = tagged_sents[size:]                          # test set is max_size-2000 long = 2637\n",
        "#defining the taggers \n",
        "t0 = nltk.DefaultTagger('NN')                                 \n",
        "tr = nltk.RegexpTagger(patterns, backoff=t0)\n",
        "t1 = nltk.UnigramTagger(train_sentences, backoff=tr)\n",
        "t2 = nltk.BigramTagger(train_sentences, backoff=t1)\n",
        "#checking accuracy of the taggers\n",
        "print(t0.accuracy(test_sentences))\n",
        "print(tr.accuracy(test_sentences))\n",
        "print(t1.accuracy(test_sentences))\n",
        "print(t2.accuracy(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YmQeGdAud-3",
        "outputId": "87243a9b-bca6-4a2b-f250-e51587bd1940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11795982196559605\n",
            "0.19379285456513895\n",
            "0.8431131961987249\n",
            "0.8547094911584265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scenario 3\n",
        "size=4636                                                     # taking the value of variable \"size\" as 4636\n",
        "train_sentences = tagged_sents[:size]                         # training set is 4636 word long (very large)\n",
        "test_sentences = tagged_sents[size:]                          # test set is max_size-4636 long = 1\n",
        "#defining the taggers \n",
        "t0 = nltk.DefaultTagger('NN')                                 \n",
        "tr = nltk.RegexpTagger(patterns, backoff=t0)\n",
        "t1 = nltk.UnigramTagger(train_sentences, backoff=tr)\n",
        "t2 = nltk.BigramTagger(train_sentences, backoff=t1)\n",
        "#checking accuracy of the taggers\n",
        "print(t0.accuracy(test_sentences))\n",
        "print(tr.accuracy(test_sentences))\n",
        "print(t1.accuracy(test_sentences))\n",
        "print(t2.accuracy(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJgVt30bueLY",
        "outputId": "bdb8beb7-b303-4102-8123-c7457e27387e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    }
  ]
}